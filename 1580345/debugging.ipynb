{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import logging\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "'''\n",
    "TO DO \n",
    "separate issuer investment\n",
    "make issuer would have company name\n",
    "\n",
    "June 30 2021\n",
    "\n",
    "start Black rock capital investment core BKCC (cik==1326003)\n",
    "'''\n",
    "# https://www.sec.gov/robots.txt\n",
    "def get_standard_name(col, choices, score_cutoff=60):\n",
    "    best_match, score = process.extractOne(col, choices)\n",
    "    if score > score_cutoff:\n",
    "        return best_match\n",
    "    return col\n",
    "\n",
    "def stopping_criterion(qtr:str)->str:\n",
    "    if qtr == '2023-12-31':\n",
    "        return '{}'.format(r'Total\\s*Cash\\s*Equivalents')\n",
    "    return '{}'.format(r'Total\\s*Investments')\n",
    "\n",
    "\n",
    "def concat(*dfs)->list:\n",
    "    final = []\n",
    "    for df in dfs:\n",
    "        final.extend(df.values.tolist())\n",
    "    return final\n",
    "\n",
    "def common_subheaders()->tuple:\n",
    "    return tuple(map(lambda header:header.replace(' ', r'\\s*'),\n",
    "        ('Advertising, Public Relations and Marketing ',\n",
    "        'Air Transportation',\n",
    "        'Amusement and Recreation',\n",
    "        'Apparel Manufacturing',\n",
    "        'Building Equipment Contractors',\n",
    "        'Business Support Services',\n",
    "        'Chemicals',\n",
    "        'Communications Equipment Manufacturing',\n",
    "        'Credit Related Activities',\n",
    "        'Computer Systems Design and Related Services',\n",
    "        'Credit (Nondepository)',\n",
    "        'Data Processing and Hosting Services',\n",
    "        'Educational Support Services',\n",
    "        'Electronic Component Manufacturing',\n",
    "        'Equipment Leasing',\n",
    "        'Facilities Support Services',\n",
    "        'Grocery Stores',\n",
    "        'Hospitals',\n",
    "        'Insurance',\n",
    "        'Lessors of Nonfinancial Licenses',\n",
    "        'Management, Scientific, and Technical Consulting Services',\n",
    "        'Motion Picture and Video Industries',\n",
    "        'Other Information Services',\n",
    "        'Other Manufacturing',\n",
    "        'Other Publishing',\n",
    "        'Other Real Estate Activities',\n",
    "        'Other Telecommunications',\n",
    "        'Plastics Manufacturing',\n",
    "        'Radio and Television Broadcasting',\n",
    "        'Real Estate Leasing',\n",
    "        'Restaurants',\n",
    "        'Retail',\n",
    "        'Satellite Telecommunications',\n",
    "        'Scientific Research and Development Services',\n",
    "        'Texttile Furnishings Mills',\n",
    "        'Traveler Arrangement',\n",
    "        'Software Publishing',\n",
    "        'Utility System Construction',\n",
    "        'Wholesalers',\n",
    "        'Wired Telecommunications Carriers',\n",
    "        'Wireless Telecommunications Carriers',\n",
    "        )\n",
    "    ))\n",
    "\n",
    "def standard_field_names()->tuple:\n",
    "    return (\n",
    "        'portfolio',\n",
    "        'footnotes',\n",
    "        'industry',\n",
    "        'rate',\n",
    "        'floor',\n",
    "        'maturity',\n",
    "        'principal amount', # TODO change stand names for more dynamic fuzzywuzzy matching\n",
    "        'cost',\n",
    "        'fair value',\n",
    "        'investment',\n",
    "        'date',\n",
    "        'subheaders',\n",
    "        'number of shares',\n",
    "        'of net assets',\n",
    "        'type',\n",
    "        'effective yield',\n",
    "        'share units',\n",
    "        'Percent of Case and Investments',\n",
    "        '\\\\% of Portfolio',\n",
    "        'issuer'\n",
    "    )\n",
    "\n",
    "def company_control_headers()->tuple:\n",
    "    return tuple(map(lambda header:header.replace(' ', r'\\s*'),\n",
    "        (\n",
    "        'Debt Investments',\n",
    "        'Debt Investments (82.23%)',\n",
    "        'Debt Investments (A)',\n",
    "        'Debt Investments (continued)',\n",
    "        'Equity Securities',\n",
    "        'Equity Securities (continued)',\n",
    "        'Cash and Cash Equivalents',\n",
    "        )\n",
    "    ))\n",
    "\n",
    "def strip_string(\n",
    "    columns_names:list,\n",
    "    standardize:bool=False\n",
    ")->tuple:\n",
    "    # columns = tuple(map(lambda col:re.sub(r'[^a-z]', '', str(col).lower()),columns_names))\n",
    "    if standardize:\n",
    "        standard_fields = standard_field_names()\n",
    "        return tuple(\n",
    "            re.sub(r'\\s+', '_',get_standard_name(col,standard_fields)) for col in columns_names\n",
    "        )\n",
    "    return tuple(re.sub(r'\\s+', '_',col) for col in columns_names)\n",
    "\n",
    "def get_key_fields(\n",
    "    df_cur:pd.DataFrame\n",
    ")->tuple:\n",
    "    important_fields = standard_field_names() + common_subheaders()\n",
    "    for idx,row in enumerate(df_cur.iterrows()):\n",
    "        found = any(any(\n",
    "            key in str(field).lower() \n",
    "            for key in important_fields)\n",
    "                    for field in row[-1].dropna().tolist()\n",
    "            )\n",
    "        if found and len(set(row[-1].dropna().tolist())) >= 4:\n",
    "            cols = df_cur.iloc[:idx + 1].apply(lambda row: ' '.join(row.dropna()), axis=0).tolist()\n",
    "            fields = strip_string(cols,standardize=found) ,idx\n",
    "            return fields\n",
    "    return strip_string(df_cur.iloc[0].tolist(),standardize=found),0\n",
    "\n",
    "\n",
    "# Function to extract date and convert to datetime object\n",
    "def extract_date(file_path):\n",
    "    # Extract date from file path (assuming date is always in 'YYYY-MM-DD' format)\n",
    "    date_str = re.search(r'\\d{4}-\\d{2}-\\d{2}', file_path).group()\n",
    "    return datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "\n",
    "\n",
    "def merge_duplicate_columns(\n",
    "    df:pd.DataFrame,\n",
    ")->pd.DataFrame:\n",
    "    duplicate_cols = df.columns[df.columns.duplicated(keep=False)]\n",
    "    for col_name in duplicate_cols.unique():\n",
    "        duplicate_data = df.loc[:, df.columns == col_name]\n",
    "        merged_data = duplicate_data.apply(lambda row: ' '.join(set(row.dropna().astype(str))), axis=1)\n",
    "        df = df.loc[:, df.columns != col_name]\n",
    "        df[col_name] = merged_data\n",
    "    return df\n",
    "\n",
    "def extract_subheaders(\n",
    "    df:pd.DataFrame,\n",
    "    control:bool,\n",
    ")->pd.DataFrame:\n",
    "    col_name = 'company_control' if control else 'Type_of_Investment'\n",
    "    if col_name in df.columns:\n",
    "        return df\n",
    "    include = df.apply(\n",
    "        lambda row: re.search('|'.join(company_control_headers() if control else common_subheaders()), str(row[0]), re.IGNORECASE) is not None,\n",
    "        axis=1\n",
    "    )  \n",
    "    \n",
    "    exclude = ~df.apply(\n",
    "        lambda row: row.astype(str).str.contains('total|Inc|Ltd|LLC|Holdings|LP|Co|Corporation', case=False, na=False).any(),\n",
    "        axis=1\n",
    "    )\n",
    "    idx = df[include & exclude].index.tolist()\n",
    "    df[col_name] = None\n",
    "    if not idx:\n",
    "        return df\n",
    "\n",
    "    prev_header = subheader = None\n",
    "    df.loc[idx[-1]:,col_name] = df.iloc[idx[-1],1] if isinstance(df.iloc[idx[-1],0],float)  else df.iloc[idx[-1],0]\n",
    "    for j,i in enumerate(idx[:-1]):\n",
    "        prev_header = subheader\n",
    "        subheader = df.iloc[i,1] if isinstance(df.iloc[i,0],float)  else df.iloc[i,0]\n",
    "        df.loc[idx[j]:idx[j+1],col_name] = subheader if subheader != '' else prev_header\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_row_duplicates(row:pd.Series)->pd.Series: \n",
    "    out = []\n",
    "    for v in row:\n",
    "        if v in out:\n",
    "            out.append(np.nan)\n",
    "        else:\n",
    "            out.append(v)\n",
    "    return pd.Series(out)\n",
    "\n",
    "def remove_regex(qtr:str)->tuple:\n",
    "    if qtr == \"2019-12-31\":\n",
    "        return re.compile(r\"TRIPLEPOINT VENTURE GROWTH BDC CORP\\. AND SUBSIDIARIES\\s+CONSOLIDATED SCHEDULE OF INVESTMENTS\\s+\\(in thousands\\)\\s+(?:\\(unaudited\\)\\s+)?As of\\s+\\w+\\s+\\d{1,2},?\\s+\\d{4}\")\n",
    "    if qtr == '2020-12-31':\n",
    "        return re.compile(r\"TRIPLEPOINT VENTURE GROWTH BDC CORP\\. AND SUBSIDIARIES\\s+CONSOLIDATED SCHEDULE OF INVESTMENTS\\s+\\(dollars in thousands\\)\\s+As of\\s+\\w+\\s+\\d{1,2},?\\s+\\d{4}\")\n",
    "    if qtr == \"2021-12-31\":\n",
    "        return re.compile(r\"TRIPLEPOINT VENTURE GROWTH BDC CORP\\. AND SUBSIDIARIES\\s+CONSOLIDATED SCHEDULE OF INVESTMENTS\\s+\\(dollars in thousands\\)\\s+As of\\s+\\w+\\s+\\d{1,2},?\\s+\\d{4}\")\n",
    "    if qtr == '2022-12-31':\n",
    "        return re.compile(r\"TRIPLEPOINT VENTURE GROWTH BDC CORP\\. AND SUBSIDIARIES\\s+CONSOLIDATED SCHEDULE OF INVESTMENTS\\s+\\(dollars in thousands\\)\\s+(?:\\(unaudited\\)\\s+)?As of\\s+\\w+\\s+\\d{1,2},?\\s+\\d{4}\")\n",
    "    if qtr in ['2023-06-30','2023-09-30','2023-12-31']:\n",
    "        return re.compile(r\"TRIPLEPOINT VENTURE GROWTH BDC CORP\\. AND SUBSIDIARIES\\s+CONSOLIDATED SCHEDULE OF INVESTMENTS\\s+\\(dollars in thousands\\)\\s+(\\(unaudited\\)\\s+)?As of\\s+\\w+\\s+\\d{1,2},\\s+\\d{4}\")\n",
    "    return re.compile(r\"^TRIPLEPOINT VENTURE GROWTH BDC CORP\\. AND SUBSIDIARIES\\s+CONSOLIDATED SCHEDULE OF INVESTMENTS\\s+\\((unaudited|dollars in thousands|in thousands)\\)\\s+\\((unaudited|dollars in thousands|in thousands)\\)?\\s+As of (January|February|March|April|May|June|July|August|September|October|November|December) \\d{1,2}, \\d{4}$|TRIPLEPOINT\\s+VENTURE\\s+GROWTH\\s+BDC\\s+CORP\\.\\s+AND\\s+SUBSIDIARIES\\s+CONSOLIDATED\\s+SCHEDULE\\s+OF\\s+INVESTMENTS\\s+\\(dollars\\s+in\\s+thousands\\)\\s+\\(unaudited\\)\\s+As\\s+of\\s+March\\s+31,\\s+2023|TRIPLEPOINT\\s+VENTURE\\s+GROWTH\\s+BDC\\s+CORP\\.\\s+AND\\s+SUBSIDIARIES\\s+CONSOLIDATED\\s+SCHEDULE\\s+OF\\s+INVESTMENTS\\s+\\(unaudited\\)\\s+\\(dollars\\s+in\\s+thousands\\)\\s+As\\s+of\\s+March\\s+31,\\s+2024\")\n",
    "    \n",
    "def _clean(\n",
    "    file_path:str,\n",
    "    regex_pattern:str=r\"^TRIPLEPOINT VENTURE GROWTH BDC CORP\\. AND SUBSIDIARIES\\s+CONSOLIDATED SCHEDULE OF INVESTMENTS\\s+\\((unaudited|dollars in thousands|in thousands)\\)\\s+\\((unaudited|dollars in thousands|in thousands)\\)?\\s+As of (January|February|March|April|May|June|July|August|September|October|November|December) \\d{1,2}, \\d{4}$|TRIPLEPOINT\\s+VENTURE\\s+GROWTH\\s+BDC\\s+CORP\\.\\s+AND\\s+SUBSIDIARIES\\s+CONSOLIDATED\\s+SCHEDULE\\s+OF\\s+INVESTMENTS\\s+\\(dollars\\s+in\\s+thousands\\)\\s+\\(unaudited\\)\\s+As\\s+of\\s+March\\s+31,\\s+2023|TRIPLEPOINT\\s+VENTURE\\s+GROWTH\\s+BDC\\s+CORP\\.\\s+AND\\s+SUBSIDIARIES\\s+CONSOLIDATED\\s+SCHEDULE\\s+OF\\s+INVESTMENTS\\s+\\(unaudited\\)\\s+\\(dollars\\s+in\\s+thousands\\)\\s+As\\s+of\\s+March\\s+31,\\s+2024\"\n",
    ")->pd.DataFrame:\n",
    "    df = pd.read_csv(file_path,index_col=0,na_values=[' ', ''])\n",
    "        \n",
    "    df.replace(['\\u200b',None, r'^\\s*$'],np.nan,regex=True,inplace=True) #':','$','%'\n",
    "    df.dropna(axis=0,how='all',inplace=True)\n",
    "    \n",
    "    df = df[~df.apply(lambda row:row.astype(str).str.match(regex_pattern).all(),axis=1)]\n",
    "    important_fields,idx = get_key_fields(df)\n",
    "    df.columns = important_fields\n",
    "    df = merge_duplicate_columns(df).reset_index(drop=True)\n",
    "    \n",
    "    duplicate_idx = df.apply(lambda row:row[pd.to_numeric(row,errors='coerce').isna()].duplicated().sum() > 1 ,axis=1)\n",
    "    clean_rows = df.loc[duplicate_idx].apply(remove_row_duplicates, axis=1).reset_index(drop=True)\n",
    "    j = 0\n",
    "    for i,flag in enumerate(duplicate_idx):\n",
    "        if not flag:\n",
    "            continue\n",
    "        df.iloc[i,:] = clean_rows.loc[j,:]\n",
    "        j += 1\n",
    "    df.replace([r'^\\s*$'],np.nan,regex=True,inplace=True) #':','$','%'\n",
    "    df.dropna(axis=1,how='all',inplace=True)\n",
    "    \n",
    "    columns = (~df.isna()).sum(axis=0) <= 3 \n",
    "    df.drop(columns=df.columns[columns],inplace=True)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def md_parse(\n",
    "    xml_file:str\n",
    "):\n",
    "    # Load HTML content\n",
    "    with open(xml_file, 'r') as file:\n",
    "        html_content = file.read()\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    # If the content is inside <pre>, get the text within it\n",
    "    pre_text = soup.find('pre').get_text()\n",
    "    # print(pre_text)\n",
    "    start = pre_text.split('Portfolio Company')[-1]\n",
    "    if start == pre_text:\n",
    "        start = pre_text.split('PORTFOLIO COMPANY')[-1]\n",
    "\n",
    "    start = 'Portfolio Company' + start[:len(start)]\n",
    "    end = start.split('NET ASSETS')[0]\n",
    "    # print(end)\n",
    "    lines = end.split('\\n')\n",
    "    data = []\n",
    "    num_cols = len(lines[0].split())\n",
    "    for line in lines:\n",
    "        line = line.replace('$','')\n",
    "        row = [np.nan]*num_cols\n",
    "        values = re.split(r'\\s{4,}', line)\n",
    "        row[:len(values)] = values\n",
    "        data.append(row)   \n",
    "\n",
    "    df = pd.DataFrame(data,columns=data[0]).dropna(axis=1,how='all')\n",
    "    important_fields,idx = get_key_fields(df)\n",
    "    df.columns = important_fields\n",
    "    return df\n",
    "\n",
    "def exceptions()->tuple:\n",
    "    return (\n",
    "        '2015-03-31\\Schedule_of_Investments_4.csv',\n",
    "        '2014-12-31\\Schedule_of_Investments_5.csv'\n",
    "    )\n",
    "\n",
    "cik = 1580345\n",
    "\n",
    "def main()->None:\n",
    "    qtrs = os.listdir('.')\n",
    "    for qtr in qtrs:\n",
    "        if '.csv' in qtr or not os.path.exists(os.path.join(qtr,f'Schedule_of_Investments_0.csv')):\n",
    "            continue\n",
    "        # qtr = '2015-03-31'\n",
    "        print(qtr)\n",
    "\n",
    "        index_list_sum = i = 0\n",
    "        soi_files = sorted([\n",
    "            os.path.join(qtr,file) \n",
    "            for file in os.listdir(os.path.join(qtr))\n",
    "            if '.csv' in file\n",
    "        ],key=lambda f: int(f.split('_')[-1].split('.')[0]))\n",
    "        df = _clean(soi_files[i],remove_regex(qtr))\n",
    "        index_list = df.apply(\n",
    "            lambda row:row.astype(str).str.contains(stopping_criterion(qtr), case=False, na=False).any(),\n",
    "            axis=1\n",
    "        )\n",
    "        index_list_sum = index_list.sum()\n",
    "        dfs = [df]     \n",
    "        i += 1\n",
    "        cols = df.columns.tolist()\n",
    "        while index_list_sum == 0:\n",
    "            if '\\\\'.join(soi_files[i].split('\\\\')[-2:]) in exceptions():\n",
    "                i += 1\n",
    "                continue\n",
    "            print(soi_files[i])\n",
    "            df = _clean(soi_files[i],remove_regex(qtr))\n",
    "            if set(list(range(10))) >= set(df.columns.tolist()):\n",
    "                df.columns = cols\n",
    "            dfs.append(df)\n",
    "            index_list = df.apply(\n",
    "                lambda row:row.astype(str).str.contains(stopping_criterion(qtr), case=False, na=False).any(),\n",
    "                axis=1\n",
    "            )\n",
    "            index_list_sum = index_list.sum()\n",
    "            i += 1\n",
    "            \n",
    "        date_final = dfs[0]\n",
    "        if len(dfs) > 1:\n",
    "            date_final = pd.concat(dfs,axis=0,ignore_index=True)#pd.DataFrame(concat(*dfs))\n",
    "        # date_final = extract_subheaders(date_final,control=True)\n",
    "        # date_final = extract_subheaders(date_final,control=False)\n",
    "\n",
    "        date_final['qtr'] = qtr.split('\\\\')[-1]\n",
    "        if not os.path.exists(os.path.join(qtr,'output')):\n",
    "            os.makedirs(os.path.join(qtr,'output'))\n",
    "        columns_to_drop = date_final.notna().sum() <= 2\n",
    "        date_final.drop(columns=columns_to_drop[columns_to_drop].index)\n",
    "        date_final.to_csv(os.path.join(qtr,'output',f'{qtr}.csv'),index=False)\n",
    "        # break\n",
    "    \n",
    "    # Use glob to find files\n",
    "    files = sorted(glob.glob(f'*/output/*.csv'), key=extract_date)\n",
    "    single_truth = pd.concat([\n",
    "        pd.read_csv(df) for df in files\n",
    "    ],axis=0,ignore_index=True)\n",
    "    single_truth.drop(columns=single_truth.columns[['Unnamed' in col for col in single_truth.columns]],inplace=True)\n",
    "    single_truth.to_csv(f'{cik}_soi_table.csv',index=False)\n",
    "    \n",
    "    \n",
    "# from utils import init_logger\n",
    "import warnings\n",
    "cik = 1580345\n",
    "# Suppress future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "# init_logger(cik)\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Venture_Growth_Stage_Company</th>\n",
       "      <th>industry</th>\n",
       "      <th>investment</th>\n",
       "      <th>number_of_shares</th>\n",
       "      <th>cost</th>\n",
       "      <th>fair_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Venture Growth Stage Company</td>\n",
       "      <td>Industry</td>\n",
       "      <td>Type of Investment</td>\n",
       "      <td>Shares</td>\n",
       "      <td>Cost</td>\n",
       "      <td>Fair Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Warrants  (2)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aerohive Networks, Inc.</td>\n",
       "      <td>Wireless Communications Equipment</td>\n",
       "      <td>Common Stock Warrants</td>\n",
       "      <td>33993</td>\n",
       "      <td>$ 153</td>\n",
       "      <td>$ 79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AirStrip Technologies, Inc.</td>\n",
       "      <td>Medical Software and Information Services</td>\n",
       "      <td>Preferred Stock Warrants</td>\n",
       "      <td>25886</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Birchbox, Inc.</td>\n",
       "      <td>E-Commerce — Personal Goods</td>\n",
       "      <td>Preferred Stock Warrants</td>\n",
       "      <td>49829</td>\n",
       "      <td>566</td>\n",
       "      <td>1487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coraid, Inc.</td>\n",
       "      <td>Data Storage</td>\n",
       "      <td>Preferred Stock Warrants</td>\n",
       "      <td>157710</td>\n",
       "      <td>317</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EndoChoice, Inc.</td>\n",
       "      <td>Medical Device and Equipment</td>\n",
       "      <td>Preferred Stock Warrants</td>\n",
       "      <td>631672</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harvest Power, Inc.</td>\n",
       "      <td>Biofuels/Biomass</td>\n",
       "      <td>Common Stock Warrants</td>\n",
       "      <td>67935</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hayneedle, Inc.</td>\n",
       "      <td>E-Commerce — Household Goods</td>\n",
       "      <td>Common Stock Warrants</td>\n",
       "      <td>400000</td>\n",
       "      <td>468</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InMobi, Pte Ltd  (1)</td>\n",
       "      <td>Advertising / Marketing</td>\n",
       "      <td>Common Stock Warrants</td>\n",
       "      <td>35000</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Inspirato, LLC</td>\n",
       "      <td>Travel and Leisure</td>\n",
       "      <td>Preferred Stock Warrants</td>\n",
       "      <td>1994</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lattice Engines, Inc.</td>\n",
       "      <td>Business Applications Software</td>\n",
       "      <td>Preferred Stock Warrants</td>\n",
       "      <td>191935</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ModCloth, Inc.</td>\n",
       "      <td>E-Commerce — Clothing and Accessories</td>\n",
       "      <td>Common Stock Warrants</td>\n",
       "      <td>419620</td>\n",
       "      <td>545</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Nutanix, Inc.</td>\n",
       "      <td>Database Software</td>\n",
       "      <td>Preferred Stock Warrants</td>\n",
       "      <td>45000</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Venture_Growth_Stage_Company                                   industry  \\\n",
       "0   Venture Growth Stage Company                                   Industry   \n",
       "1                  Warrants  (2)                                        NaN   \n",
       "2        Aerohive Networks, Inc.          Wireless Communications Equipment   \n",
       "3    AirStrip Technologies, Inc.  Medical Software and Information Services   \n",
       "4                 Birchbox, Inc.                E-Commerce — Personal Goods   \n",
       "5                   Coraid, Inc.                               Data Storage   \n",
       "6               EndoChoice, Inc.               Medical Device and Equipment   \n",
       "7            Harvest Power, Inc.                           Biofuels/Biomass   \n",
       "8                Hayneedle, Inc.               E-Commerce — Household Goods   \n",
       "9           InMobi, Pte Ltd  (1)                    Advertising / Marketing   \n",
       "10                Inspirato, LLC                         Travel and Leisure   \n",
       "11         Lattice Engines, Inc.             Business Applications Software   \n",
       "12                ModCloth, Inc.      E-Commerce — Clothing and Accessories   \n",
       "13                 Nutanix, Inc.                          Database Software   \n",
       "\n",
       "                  investment number_of_shares   cost  fair_value  \n",
       "0         Type of Investment           Shares   Cost  Fair Value  \n",
       "1                        NaN              NaN    NaN         NaN  \n",
       "2      Common Stock Warrants            33993  $ 153        $ 79  \n",
       "3   Preferred Stock Warrants            25886     93          93  \n",
       "4   Preferred Stock Warrants            49829    566        1487  \n",
       "5   Preferred Stock Warrants           157710    317         317  \n",
       "6   Preferred Stock Warrants           631672    149         149  \n",
       "7      Common Stock Warrants            67935     77          77  \n",
       "8      Common Stock Warrants           400000    468         468  \n",
       "9      Common Stock Warrants            35000     27          27  \n",
       "10  Preferred Stock Warrants             1994     37          37  \n",
       "11  Preferred Stock Warrants           191935     39          39  \n",
       "12     Common Stock Warrants           419620    545         545  \n",
       "13  Preferred Stock Warrants            45000     77          77  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r'C:\\Users\\pysol\\Desktop\\projects\\sec_filings\\1580345\\2014-03-31\\Schedule_of_Investments_4.csv'\n",
    "df = _clean(file_path)\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sec_windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
