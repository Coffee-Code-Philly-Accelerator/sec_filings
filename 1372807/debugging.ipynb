{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2008-12-31'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_1.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_2.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_3.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_4.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_5.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_6.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_7.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_8.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_9.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_10.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_11.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_12.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_13.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2008-12-31\\\\Schedule_of_Investments_14.csv'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 16 instead of 15",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 354\u001b[0m\n\u001b[0;32m    350\u001b[0m cik \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1372807\u001b[39m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# logger = init_logger(cik)\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# logger.info(cik)\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[83], line 319\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    317\u001b[0m display(soi_files[i])\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# display(merged_pair_idxs)\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m df,merged_pair_idxs \u001b[38;5;241m=\u001b[39m \u001b[43m_clean\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoi_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexcept_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmerged_pair_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_pair_idxs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msoi_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m dfs\u001b[38;5;241m.\u001b[39mappend(df)\n\u001b[0;32m    321\u001b[0m index_list \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m row:row\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(stopping_criterion(qtr), case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39many(),\n\u001b[0;32m    323\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    324\u001b[0m )\n",
      "Cell \u001b[1;32mIn[83], line 255\u001b[0m, in \u001b[0;36m_clean\u001b[1;34m(file_path, except_rows, merged_pair_idxs)\u001b[0m\n\u001b[0;32m    252\u001b[0m     important_fields \u001b[38;5;241m=\u001b[39m strip_string(get_header_rows(df),standardize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;66;03m#get_key_fields(df)\u001b[39;00m\n\u001b[0;32m    253\u001b[0m     df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m important_fields\n\u001b[1;32m--> 255\u001b[0m df,merge_pair_idxs \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_duplicate_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmerged_pair_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_pair_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m duplicate_idx \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row:row[pd\u001b[38;5;241m.\u001b[39mto_numeric(row,errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39misna()]\u001b[38;5;241m.\u001b[39mduplicated()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m ,axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    257\u001b[0m clean_rows \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[duplicate_idx]\u001b[38;5;241m.\u001b[39mapply(remove_row_duplicates, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[83], line 193\u001b[0m, in \u001b[0;36mmerge_duplicate_columns\u001b[1;34m(df, merged_pair_idxs)\u001b[0m\n\u001b[0;32m    191\u001b[0m     mask \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m==\u001b[39m col_name\n\u001b[0;32m    192\u001b[0m     merged_pair_idxs[col_name] \u001b[38;5;241m=\u001b[39m mask\n\u001b[1;32m--> 193\u001b[0m duplicate_data \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    194\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m duplicate_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mset\u001b[39m(row\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m))), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    195\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;241m~\u001b[39mmask]\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:1377\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:1020\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 1020\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:1413\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:1209\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getbool_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, axis: AxisInt):\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;66;03m# caller is responsible for ensuring non-None axis\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1209\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m     inds \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(inds, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:2681\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_like(result):\n\u001b[0;32m   2678\u001b[0m     \u001b[38;5;66;03m# GH 33924\u001b[39;00m\n\u001b[0;32m   2679\u001b[0m     \u001b[38;5;66;03m# key may contain nan elements, check_array_indexer needs bool array\u001b[39;00m\n\u001b[0;32m   2680\u001b[0m     result \u001b[38;5;241m=\u001b[39m pd_array(result, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m-> 2681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_array_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:539\u001b[0m, in \u001b[0;36mcheck_array_indexer\u001b[1;34m(array, indexer)\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;66;03m# GH26658\u001b[39;00m\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(array):\n\u001b[1;32m--> 539\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoolean index has wrong length: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(indexer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(array)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m         )\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer_dtype(dtype):\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: Boolean index has wrong length: 16 instead of 15"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import datetime\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "sys.path.insert(0, '../') \n",
    "# from utils import init_logger\n",
    "\n",
    "def common_subheaders()->tuple:\n",
    "    return tuple(map(lambda header:header.replace(' ', r'\\s*'),\n",
    "        ('Advertising, Public Relations and Marketing ',\n",
    "        'Air Transportation',\n",
    "        'Amusement and Recreation',\n",
    "        'Apparel Manufacturing',\n",
    "        'Building Equipment Contractors',\n",
    "        'Business Support Services',\n",
    "        'Chemicals',\n",
    "        'Communications Equipment Manufacturing',\n",
    "        'Credit Related Activities',\n",
    "        'Computer Systems Design and Related Services',\n",
    "        'Credit (Nondepository)',\n",
    "        'Data Processing and Hosting Services',\n",
    "        'Educational Support Services',\n",
    "        'Electronic Component Manufacturing',\n",
    "        'Equipment Leasing',\n",
    "        'Facilities Support Services',\n",
    "        'Grocery Stores',\n",
    "        'Hospitals',\n",
    "        'Insurance',\n",
    "        'Lessors of Nonfinancial Licenses',\n",
    "        'Management, Scientific, and Technical Consulting Services',\n",
    "        'Motion Picture and Video Industries',\n",
    "        'Other Information Services',\n",
    "        'Other Manufacturing',\n",
    "        'Other Publishing',\n",
    "        'Other Real Estate Activities',\n",
    "        'Other Telecommunications',\n",
    "        'Plastics Manufacturing',\n",
    "        'Radio and Television Broadcasting',\n",
    "        'Real Estate Leasing',\n",
    "        'Restaurants',\n",
    "        'Retail',\n",
    "        'Satellite Telecommunications',\n",
    "        'Scientific Research and Development Services',\n",
    "        'Texttile Furnishings Mills',\n",
    "        'Traveler Arrangement',\n",
    "        'Software Publishing',\n",
    "        'Utility System Construction',\n",
    "        'Wholesalers',\n",
    "        'Wired Telecommunications Carriers',\n",
    "        'Wireless Telecommunications Carriers',\n",
    "        )\n",
    "    ))\n",
    "\n",
    "\n",
    "def standard_field_names()->tuple:\n",
    "    return (\n",
    "        'Portfolio Company',\n",
    "        'Portfolio Company /Principal Business',\n",
    "        'Investment /Interest Rate /Maturity',\n",
    "        'Principal',\n",
    "        'Cost',\n",
    "        'Value',\n",
    "        'Percent of Class Held',\n",
    "        'Investment',\n",
    "        'CDO Fund Investments',\n",
    "        'Percent of Interests Held',\n",
    "        'Industry',\n",
    "        'Spread Above Index',\n",
    "        'Aquisition Date',\n",
    "        'Interest Rate',\n",
    "        'Maturity',\n",
    "        'Principal/Shares',\n",
    "        'Investment Type',\n",
    "        'of Net Assets',\n",
    "        'business description',\n",
    "        'type of investment',\n",
    "        'investment date',\n",
    "        'reference rate and spread',\n",
    "        'pik rate',\n",
    "        'maturity date',\n",
    "        'cost',\n",
    "        'footnotes',\n",
    "        'industry',\n",
    "        'principal amount', # TODO change stand names for more dynamic fuzzywuzzy matching\n",
    "        'fair value',\n",
    "    )\n",
    "\n",
    "    \n",
    "def company_control_headers()->tuple:\n",
    "    return tuple(map(lambda header:header.replace(' ', r'\\s*'),\n",
    "        (\n",
    "        'Debt Investments',\n",
    "        'Debt Investments (82.23%)',\n",
    "        'Debt Investments (A)',\n",
    "        'Debt Investments (continued)',\n",
    "        'Equity Securities',\n",
    "        'Equity Securities (continued)',\n",
    "        'Cash and Cash Equivalents',\n",
    "        )\n",
    "    ))\n",
    "\n",
    "def exceptions()->tuple:\n",
    "    return (\n",
    "        '2006-12-31\\\\Schedule_of_Investments_1.csv', \n",
    "        '2006-12-31\\\\Schedule_of_Investments_3.csv', \n",
    "        '2008-03-31\\\\Schedule_of_Investments_7.csv',\n",
    "        '2008-03-31\\\\Schedule_of_Investments_8.csv',  \n",
    "        '2008-12-31\\\\Schedule_of_Investments_6.csv',\n",
    "        '2008-12-31\\\\Schedule_of_Investments_11.csv',\n",
    "        '2008-12-31\\\\Schedule_of_Investments_13.csv'\n",
    "\n",
    "    )\n",
    "\n",
    "def except_rows()->tuple:\n",
    "    return (\n",
    "        'Timet',\n",
    "    )\n",
    "\n",
    "# https://www.sec.gov/robots.txt\n",
    "def get_standard_name(col, choices, score_cutoff=60):\n",
    "    best_match, score = process.extractOne(col, choices)\n",
    "    if score > score_cutoff:\n",
    "        return best_match\n",
    "    return col\n",
    "\n",
    "def stopping_criterion(qtr:str)->str:\n",
    "    return '{}'.format(r'Total\\s*Investments')\n",
    "\n",
    " \n",
    "def concat(*dfs)->list:\n",
    "    final = []\n",
    "    for df in dfs:\n",
    "        final.extend(df.values.tolist())\n",
    "    return final\n",
    "\n",
    "    \n",
    "def get_key_fields(\n",
    "    df_cur:pd.DataFrame,\n",
    ")->tuple:\n",
    "    important_fields = standard_field_names() + common_subheaders()\n",
    "    for idx,row in enumerate(df_cur.iterrows()):\n",
    "        found = any(any(\n",
    "            key in str(field).lower() \n",
    "            for key in important_fields)\n",
    "                    for field in row[-1].dropna().tolist()\n",
    "            )\n",
    "        if found and len(set(row[-1].dropna().tolist())) >= 6:\n",
    "            cols = df_cur.iloc[:idx + 1].apply(lambda row: ' '.join(row.dropna()), axis=0).tolist()\n",
    "            fields = strip_string(cols,standardize=found) \n",
    "            return fields\n",
    "    return strip_string(df_cur.iloc[0].tolist())\n",
    "\n",
    "def strip_string(\n",
    "    columns_names:list,\n",
    "    standardize:bool=False\n",
    ")->tuple:\n",
    "    # columns = tuple(map(lambda col:re.sub(r'[^a-z]', '', str(col).lower()),columns_names))\n",
    "    if standardize:\n",
    "        standard_fields = standard_field_names()\n",
    "        return tuple(\n",
    "            re.sub(r'\\s+', '_',get_standard_name(str(col),standard_fields)) for col in columns_names\n",
    "        )\n",
    "    return tuple(re.sub(r'\\s+', '_',str(col)) for col in columns_names)\n",
    "\n",
    "\n",
    "# Function to extract date and convert to datetime object\n",
    "def extract_date(file_path):\n",
    "    # Extract date from file path (assuming date is always in 'YYYY-MM-DD' format)\n",
    "    date_str = re.search(r'\\d{4}-\\d{2}-\\d{2}', file_path).group()\n",
    "    return datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "\n",
    "\n",
    "def merge_duplicate_columns(\n",
    "    df:pd.DataFrame,\n",
    "    merged_pair_idxs:dict={}\n",
    ")->pd.DataFrame:\n",
    "    duplicate_cols = merged_pair_idxs.keys()\n",
    "    flag = not merged_pair_idxs.keys()\n",
    "    if flag: \n",
    "        duplicate_cols = df.columns.unique() \n",
    "    for col_name in duplicate_cols:\n",
    "        mask = merged_pair_idxs.get(col_name)\n",
    "        if flag:\n",
    "            mask = df.columns == col_name\n",
    "            merged_pair_idxs[col_name] = mask\n",
    "        duplicate_data = df.loc[:, mask]\n",
    "        merged_data = duplicate_data.apply(lambda row: ' '.join(set(row.dropna().astype(str))), axis=1)\n",
    "        df = df.loc[:, ~mask]\n",
    "        df[col_name] = merged_data\n",
    "    return df.reset_index(drop=True),merged_pair_idxs\n",
    "\n",
    "def extract_subheaders(\n",
    "    df:pd.DataFrame,\n",
    "    control:bool,\n",
    ")->pd.DataFrame:\n",
    "    col_name = 'company_control' if control else 'Type_of_Investment'\n",
    "    if col_name in df.columns:\n",
    "        return df\n",
    "    include = df.apply(\n",
    "        lambda row: re.search('|'.join(company_control_headers() if control else common_subheaders()), str(row[0]), re.IGNORECASE) is not None,\n",
    "        axis=1\n",
    "    )  \n",
    "    \n",
    "    exclude = ~df.apply(\n",
    "        lambda row: row.astype(str).str.contains('total|Inc|Ltd|LLC|Holdings|LP|Co|Corporation', case=False, na=False).any(),\n",
    "        axis=1\n",
    "    )\n",
    "    idx = df[include & exclude].index.tolist()\n",
    "    df[col_name] = None\n",
    "    if not idx:\n",
    "        return df\n",
    "\n",
    "    prev_header = subheader = None\n",
    "    df.loc[idx[-1]:,col_name] = df.iloc[idx[-1],1] if isinstance(df.iloc[idx[-1],0],float)  else df.iloc[idx[-1],0]\n",
    "    for j,i in enumerate(idx[:-1]):\n",
    "        prev_header = subheader\n",
    "        subheader = df.iloc[i,1] if isinstance(df.iloc[i,0],float)  else df.iloc[i,0]\n",
    "        df.loc[idx[j]:idx[j+1],col_name] = subheader if subheader != '' else prev_header\n",
    "    return df\n",
    "\n",
    "\n",
    "def remove_row_duplicates(row:pd.Series)->pd.Series: \n",
    "    out = []\n",
    "    for v in row:\n",
    "        if v in out and not str(v).replace('$','').isnumeric():\n",
    "            out.append(np.nan)\n",
    "        else:\n",
    "            out.append(v)\n",
    "    return pd.Series(out)\n",
    "\n",
    "  \n",
    "\n",
    "def _clean(\n",
    "    file_path:str,\n",
    "    except_rows:str,\n",
    "    merged_pair_idxs:dict={},\n",
    ")->pd.DataFrame:\n",
    "    df = pd.read_csv(file_path,index_col=0,na_values=[' ', ''])\n",
    "    # df.replace(['\\xa0','\\u200b',r'^\\s$',r'^\\s%'],np.nan,regex=True,inplace=True) #':','$','%' r'^\\s*$',r'^\\s*%'\n",
    "    df.replace(['\\xa0','\\u200b',r'^\\s*$',r'^\\s*%',' ','˄'],'',regex=True,inplace=True)\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    df.dropna(axis=0,how='all',inplace=True)\n",
    "    df = df[~df.apply(lambda row:row.astype(str).str.contains(except_rows,case=False, na=False).any(),axis=1)]\n",
    "    if not merged_pair_idxs:\n",
    "        important_fields = strip_string(get_header_rows(df),standardize=True)#get_key_fields(df)\n",
    "        df.columns = important_fields\n",
    "\n",
    "    df,merge_pair_idxs = merge_duplicate_columns(df,merged_pair_idxs=merged_pair_idxs)\n",
    "    duplicate_idx = df.apply(lambda row:row[pd.to_numeric(row,errors='coerce').isna()].duplicated().sum() > 1 ,axis=1)\n",
    "    clean_rows = df.loc[duplicate_idx].apply(remove_row_duplicates, axis=1).reset_index(drop=True)\n",
    "    j = 0\n",
    "    for i,flag in enumerate(duplicate_idx):\n",
    "        if not flag:\n",
    "            continue\n",
    "        df.iloc[i,:] = clean_rows.loc[j,:]\n",
    "        j += 1\n",
    "    df.replace([r'^\\s*$'],np.nan,regex=True,inplace=True) #':','$','%'\n",
    "    df.dropna(axis=1,how='all',inplace=True)\n",
    "    \n",
    "    columns = (~df.isna()).sum(axis=0) <= 4  if df.shape[0] > 12 else 1\n",
    "    df.drop(columns=df.columns[columns],inplace=True)\n",
    "    return df.reset_index(drop=True),merge_pair_idxs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_header_rows(\n",
    "    df_cur:pd.DataFrame,\n",
    ")->tuple:\n",
    "    for idx,row in df_cur.iterrows():\n",
    "        found = any(str(v).replace(\"$\",'').replace(\"%\",'').isnumeric() for v in row)\n",
    "        if found:\n",
    "            out = df_cur.iloc[:idx,:].apply(lambda row: ' '.join(row[row.notna()].values), axis=0)\n",
    "            return out\n",
    "    \n",
    "    return strip_string(df_cur.iloc[0].tolist())\n",
    "\n",
    "\n",
    "def main()->None:\n",
    "    qtrs = os.listdir('.')\n",
    "    ex = exceptions()\n",
    "    ex_rows = '|'.join(except_rows())\n",
    "    for qtr in qtrs:\n",
    "        if '.csv' in qtr or not os.path.exists(os.path.join(qtr,f'Schedule_of_Investments_0.csv')):\n",
    "            continue\n",
    "        qtr = '2008-12-31'\n",
    "        # logger.info(qtr)\n",
    "        display(qtr)\n",
    "        index_list_sum = i = 0\n",
    "        soi_files = sorted([\n",
    "            os.path.join(qtr,file) \n",
    "            for file in os.listdir(qtr)\n",
    "            if file.endswith('.csv')\n",
    "        ],key=lambda f: int(f.split('_')[-1].split('.')[0]))\n",
    "        # soi_files = [f for f in soi_files] # if f not in ex]\n",
    "        df,merged_pair_idxs = _clean(soi_files[i],except_rows=ex_rows,merged_pair_idxs={})\n",
    "        if soi_files[i] in ex:\n",
    "            merged_pair_idxs = {}\n",
    "\n",
    "        index_list = df.apply(\n",
    "            lambda row:row.astype(str).str.contains(stopping_criterion(qtr), case=False, na=False).any(),\n",
    "            axis=1\n",
    "        )\n",
    "        index_list_sum = index_list.sum()\n",
    "        dfs = [df]     \n",
    "        i += 1\n",
    "\n",
    "        while index_list_sum == 0:\n",
    "            # logger.info(soi_files[i])\n",
    "            display(soi_files[i])\n",
    "            # display(merged_pair_idxs)\n",
    "            df,merged_pair_idxs = _clean(soi_files[i],except_rows=ex_rows,merged_pair_idxs=merged_pair_idxs if soi_files[i] not in ex else {})\n",
    "            dfs.append(df)\n",
    "            index_list = df.apply(\n",
    "                lambda row:row.astype(str).str.contains(stopping_criterion(qtr), case=False, na=False).any(),\n",
    "                axis=1\n",
    "            )\n",
    "            index_list_sum = index_list.sum()\n",
    "            i += 1\n",
    "        date_final = dfs[0]\n",
    "        if len(dfs) > 1:\n",
    "            date_final = pd.concat(dfs,axis=0,ignore_index=True)#pd.DataFrame(concat(*dfs))\n",
    "        # date_final = extract_subheaders(date_final,control=True)\n",
    "        # date_final = extract_subheaders(date_final,control=False)\n",
    "\n",
    "        date_final['qtr'] = qtr.split('\\\\')[-1]\n",
    "        if not os.path.exists(os.path.join(qtr,'output')):\n",
    "            os.makedirs(os.path.join(qtr,'output'))\n",
    "        columns_to_drop = date_final.notna().sum() <= 2\n",
    "        date_final.drop(columns=columns_to_drop[columns_to_drop].index)\n",
    "        date_final.to_csv(os.path.join(qtr,'output',f'{qtr}.csv'),index=False)\n",
    "        break\n",
    "    \n",
    "    # Use glob to find files\n",
    "    files = sorted(glob.glob(f'*/output/*.csv'), key=extract_date)\n",
    "    single_truth = pd.concat([\n",
    "        pd.read_csv(df) for df in files\n",
    "    ],axis=0,ignore_index=True)\n",
    "    single_truth.drop(columns=single_truth.columns[['Unnamed' in col for col in single_truth.columns]],inplace=True)\n",
    "    single_truth.to_csv(f'{cik}_soi_table.csv',index=False)\n",
    "    \n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "cik = 1372807\n",
    "# logger = init_logger(cik)\n",
    "# logger.info(cik)\n",
    "\n",
    "main()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TimeDepositsandMoneyMarketAccount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TimeDepositsandMoneyMarketAccount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investment</td>\n",
       "      <td>Yield</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cost</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Value2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USBankEurodollarSweepCL2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TimeDeposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>10462702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10462702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JPMorganAssetAccount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TimeDeposit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1723295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1723295</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JPMorganBusinessMoneyMarketAccount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MoneyMarketAccount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.19</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TotalInvestmentinTimeDepositandMoneyMarketAcco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>12186007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12186007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TotalInvestments5(205%ofnetassetvalueatfairvalue)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$</td>\n",
       "      <td>546626619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>514225273</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0    1  \\\n",
       "0                   TimeDepositsandMoneyMarketAccount  NaN   \n",
       "2                   TimeDepositsandMoneyMarketAccount  NaN   \n",
       "3                            USBankEurodollarSweepCL2  NaN   \n",
       "5                                JPMorganAssetAccount  NaN   \n",
       "7                  JPMorganBusinessMoneyMarketAccount  NaN   \n",
       "9   TotalInvestmentinTimeDepositandMoneyMarketAcco...  NaN   \n",
       "11  TotalInvestments5(205%ofnetassetvalueatfairvalue)  NaN   \n",
       "\n",
       "                     2      3    4     5    6     7    8          9  10  \\\n",
       "0                  NaN    NaN  NaN   NaN  NaN   NaN  NaN        NaN NaN   \n",
       "2           Investment  Yield  NaN   NaN  NaN  Cost  NaN        NaN NaN   \n",
       "3          TimeDeposit    NaN  NaN  0.10        NaN    $   10462702 NaN   \n",
       "5          TimeDeposit    NaN  NaN  0.20        NaN  NaN    1723295 NaN   \n",
       "7   MoneyMarketAccount    NaN  NaN  0.19        NaN  NaN         10 NaN   \n",
       "9                  NaN    NaN  NaN   NaN  NaN   NaN    $   12186007 NaN   \n",
       "11                 NaN    NaN  NaN   NaN  NaN   NaN    $  546626619 NaN   \n",
       "\n",
       "        11   12         13  14  \n",
       "0      NaN  NaN        NaN NaN  \n",
       "2   Value2  NaN        NaN NaN  \n",
       "3      NaN  NaN   10462702 NaN  \n",
       "5      NaN  NaN    1723295 NaN  \n",
       "7      NaN  NaN         10 NaN  \n",
       "9      NaN  NaN   12186007 NaN  \n",
       "11     NaN  NaN  514225273 NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Boolean index has wrong length: 16 instead of 15",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 86\u001b[0m\n\u001b[0;32m     84\u001b[0m ex \u001b[38;5;241m=\u001b[39m exceptions()\n\u001b[0;32m     85\u001b[0m ex_rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(except_rows())\n\u001b[1;32m---> 86\u001b[0m df,merged_pair_idxs \u001b[38;5;241m=\u001b[39m \u001b[43m_clean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mexcept_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mex_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmerged_pair_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_pair_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m display(df)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# display(merged_pair_idxs)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[84], line 62\u001b[0m, in \u001b[0;36m_clean\u001b[1;34m(file_path, except_rows, merged_pair_idxs)\u001b[0m\n\u001b[0;32m     60\u001b[0m     df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m important_fields\n\u001b[0;32m     61\u001b[0m display(df)\n\u001b[1;32m---> 62\u001b[0m df,merge_pair_idxs \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_duplicate_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmerged_pair_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_pair_idxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m df\u001b[38;5;241m.\u001b[39mreplace([\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*$\u001b[39m\u001b[38;5;124m'\u001b[39m],np\u001b[38;5;241m.\u001b[39mnan,regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m#':','$','%'\u001b[39;00m\n\u001b[0;32m     65\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[83], line 193\u001b[0m, in \u001b[0;36mmerge_duplicate_columns\u001b[1;34m(df, merged_pair_idxs)\u001b[0m\n\u001b[0;32m    191\u001b[0m     mask \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m==\u001b[39m col_name\n\u001b[0;32m    192\u001b[0m     merged_pair_idxs[col_name] \u001b[38;5;241m=\u001b[39m mask\n\u001b[1;32m--> 193\u001b[0m duplicate_data \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    194\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m duplicate_data\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mset\u001b[39m(row\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m))), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    195\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;241m~\u001b[39mmask]\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:1377\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:1020\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_null_slice(key):\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m-> 1020\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m retval\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:1413\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1412\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:1209\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getbool_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, axis: AxisInt):\n\u001b[0;32m   1207\u001b[0m     \u001b[38;5;66;03m# caller is responsible for ensuring non-None axis\u001b[39;00m\n\u001b[0;32m   1208\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1209\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m     inds \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(inds, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexing.py:2681\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_array_like(result):\n\u001b[0;32m   2678\u001b[0m     \u001b[38;5;66;03m# GH 33924\u001b[39;00m\n\u001b[0;32m   2679\u001b[0m     \u001b[38;5;66;03m# key may contain nan elements, check_array_indexer needs bool array\u001b[39;00m\n\u001b[0;32m   2680\u001b[0m     result \u001b[38;5;241m=\u001b[39m pd_array(result, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m-> 2681\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_array_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pysol\\Desktop\\projects\\sec_filings\\sec_windows\\lib\\site-packages\\pandas\\core\\indexers\\utils.py:539\u001b[0m, in \u001b[0;36mcheck_array_indexer\u001b[1;34m(array, indexer)\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;66;03m# GH26658\u001b[39;00m\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(array):\n\u001b[1;32m--> 539\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBoolean index has wrong length: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(indexer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(array)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    542\u001b[0m         )\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer_dtype(dtype):\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: Boolean index has wrong length: 16 instead of 15"
     ]
    }
   ],
   "source": [
    "file_path = r'2008-12-31\\\\Schedule_of_Investments_14.csv'\n",
    "\n",
    "\n",
    "def standard_field_names()->tuple:\n",
    "    return (\n",
    "        'Portfolio Company',\n",
    "        'Portfolio Company /Principal Business',\n",
    "        'Investment /Interest Rate /Maturity',\n",
    "        'Principal',\n",
    "        'Cost',\n",
    "        'Value',\n",
    "        'Percent of Class Held',\n",
    "        'Investment',\n",
    "        'CDO Fund Investments',\n",
    "        'Percent of Interests Held',\n",
    "        'Industry',\n",
    "        'Spread Above Index',\n",
    "        'Aquisition Date',\n",
    "        'Interest Rate',\n",
    "        'Maturity',\n",
    "        'Principal/Shares',\n",
    "        'Investment Type',\n",
    "        'of Net Assets',\n",
    "        'business description',\n",
    "        'type of investment',\n",
    "        'investment date',\n",
    "        'reference rate and spread',\n",
    "        'pik rate',\n",
    "        'maturity date',\n",
    "        'cost',\n",
    "        'footnotes',\n",
    "        'industry',\n",
    "        'principal amount', # TODO change stand names for more dynamic fuzzywuzzy matching\n",
    "        'fair value',\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def _clean(\n",
    "    file_path:str,\n",
    "    except_rows:str,\n",
    "    merged_pair_idxs:dict={},\n",
    ")->pd.DataFrame:\n",
    "    df = pd.read_csv(file_path,index_col=0,na_values=[' ', ''])\n",
    "    # df.replace(['\\xa0','\\u200b',r'^\\s$',r'^\\s%'],np.nan,regex=True,inplace=True) #':','$','%' r'^\\s*$',r'^\\s*%'\n",
    "    df.replace(['\\xa0','\\u200b',r'^\\s*$',r'^\\s*%',' ','˄'],'',regex=True,inplace=True)\n",
    "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    df.dropna(axis=0,how='all',inplace=True)\n",
    "    df = df[~df.apply(lambda row:row.astype(str).str.contains(except_rows,case=False, na=False).any(),axis=1)]\n",
    "    duplicate_idx = df.apply(lambda row:row[pd.to_numeric(row,errors='coerce').isna()].duplicated().sum() > 1 ,axis=1)\n",
    "    clean_rows = df.loc[duplicate_idx].apply(remove_row_duplicates, axis=1).reset_index(drop=True)\n",
    "    j = 0\n",
    "    for i,flag in enumerate(duplicate_idx):\n",
    "        if not flag:\n",
    "            continue\n",
    "        df.iloc[i,:] = clean_rows.loc[j,:]\n",
    "        j += 1\n",
    "    if not merged_pair_idxs:\n",
    "        important_fields = strip_string(get_header_rows(df),standardize=True)#get_key_fields(df)\n",
    "        df.columns = important_fields\n",
    "    display(df)\n",
    "    df,merge_pair_idxs = merge_duplicate_columns(df,merged_pair_idxs=merged_pair_idxs)\n",
    "\n",
    "    df.replace([r'^\\s*$'],np.nan,regex=True,inplace=True) #':','$','%'\n",
    "    df.dropna(axis=1,how='all',inplace=True)\n",
    "    \n",
    "    columns = (~df.isna()).sum(axis=0) <= 4  if df.shape[0] > 12 else 1\n",
    "    df.drop(columns=df.columns[columns],inplace=True)\n",
    "    return df.reset_index(drop=True),merge_pair_idxs\n",
    "\n",
    "\n",
    "merged_pair_idxs = {'Portfolio_Company_/Principal_Business': np.array([ True, False, False, False, False, False, False, False, False,\n",
    "        False, False, False, False, False, False, False]),\n",
    " '': np.array([ True, False,  True, False, False, False,  True, False, False,\n",
    "        False,  True, False, False, False,  True, False]),\n",
    " 'Investment': np.array([ True, False, False, False, False, False, False, False, False,\n",
    "        False, False, False]),\n",
    " 'Percent_of_Interests_Held': np.array([ True,  True,  True, False, False, False, False, False, False,\n",
    "        False, False, False]),\n",
    " 'Cost': np.array([ True,  True,  True, False, False, False, False, False, False,\n",
    "        False]),\n",
    " 'Value': np.array([ True,  True,  True, False, False, False, False, False])}\n",
    "\n",
    "ex = exceptions()\n",
    "ex_rows = '|'.join(except_rows())\n",
    "df,merged_pair_idxs = _clean(file_path,except_rows=ex_rows,merged_pair_idxs=merged_pair_idxs)\n",
    "display(df)\n",
    "# display(merged_pair_idxs)\n",
    "index_list = df.apply(\n",
    "    lambda row:row.astype(str).str.contains(stopping_criterion(None), case=False, na=False).any(),\n",
    "    axis=1\n",
    ")\n",
    "index_list_sum = index_list.sum()\n",
    "index_list_sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sec_windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
